{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fca560f8-ad8e-464a-8ee8-2ecf539a6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "600ad472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"IMDBDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e62362f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c9b641a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 50000, dtype: object>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "524338a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1806c0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "85991781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing HTML text.\n",
    "import re  #re is regular expression (regex)\n",
    "df['clean_text']=df['review'].apply(lambda x:re.sub(\"<.*?>\",\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5ea933e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2ed3b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing white spaces and special characters.\n",
    "df['clean_text']=df['clean_text'].apply(lambda x:re.sub(r'[^\\w\\s]',\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9e6aed81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production The filming technique is very unassuming very oldtimeBBC fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece The actors are extremely well chosen Michael Sheen not only has got all the polari but he has all the voices down pat too You can truly see the seamless editing guided by the references to Williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece A masterful production about one of the great masters of comedy and his life The realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears It plays on our knowledge and our senses particularly with the scenes concerning Orton and Halliwell and the sets particularly of their flat with Halliwells murals decorating every surface are terribly well done'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e294fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to upper/lower case.\n",
    "df['clean_text']=df['clean_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c04b5fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ddf595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f190df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3f652a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aditya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing text.\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "df['tokenized_text']=df['clean_text'].apply(lambda x:word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3d921cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'wonderful',\n",
       " 'little',\n",
       " 'production',\n",
       " 'the',\n",
       " 'filming',\n",
       " 'technique',\n",
       " 'is',\n",
       " 'very',\n",
       " 'unassuming',\n",
       " 'very',\n",
       " 'oldtimebbc',\n",
       " 'fashion',\n",
       " 'and',\n",
       " 'gives',\n",
       " 'a',\n",
       " 'comforting',\n",
       " 'and',\n",
       " 'sometimes',\n",
       " 'discomforting',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'realism',\n",
       " 'to',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'piece',\n",
       " 'the',\n",
       " 'actors',\n",
       " 'are',\n",
       " 'extremely',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'not',\n",
       " 'only',\n",
       " 'has',\n",
       " 'got',\n",
       " 'all',\n",
       " 'the',\n",
       " 'polari',\n",
       " 'but',\n",
       " 'he',\n",
       " 'has',\n",
       " 'all',\n",
       " 'the',\n",
       " 'voices',\n",
       " 'down',\n",
       " 'pat',\n",
       " 'too',\n",
       " 'you',\n",
       " 'can',\n",
       " 'truly',\n",
       " 'see',\n",
       " 'the',\n",
       " 'seamless',\n",
       " 'editing',\n",
       " 'guided',\n",
       " 'by',\n",
       " 'the',\n",
       " 'references',\n",
       " 'to',\n",
       " 'williams',\n",
       " 'diary',\n",
       " 'entries',\n",
       " 'not',\n",
       " 'only',\n",
       " 'is',\n",
       " 'it',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'the',\n",
       " 'watching',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'terrificly',\n",
       " 'written',\n",
       " 'and',\n",
       " 'performed',\n",
       " 'piece',\n",
       " 'a',\n",
       " 'masterful',\n",
       " 'production',\n",
       " 'about',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'great',\n",
       " 'masters',\n",
       " 'of',\n",
       " 'comedy',\n",
       " 'and',\n",
       " 'his',\n",
       " 'life',\n",
       " 'the',\n",
       " 'realism',\n",
       " 'really',\n",
       " 'comes',\n",
       " 'home',\n",
       " 'with',\n",
       " 'the',\n",
       " 'little',\n",
       " 'things',\n",
       " 'the',\n",
       " 'fantasy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'guard',\n",
       " 'which',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'use',\n",
       " 'the',\n",
       " 'traditional',\n",
       " 'dream',\n",
       " 'techniques',\n",
       " 'remains',\n",
       " 'solid',\n",
       " 'then',\n",
       " 'disappears',\n",
       " 'it',\n",
       " 'plays',\n",
       " 'on',\n",
       " 'our',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'our',\n",
       " 'senses',\n",
       " 'particularly',\n",
       " 'with',\n",
       " 'the',\n",
       " 'scenes',\n",
       " 'concerning',\n",
       " 'orton',\n",
       " 'and',\n",
       " 'halliwell',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sets',\n",
       " 'particularly',\n",
       " 'of',\n",
       " 'their',\n",
       " 'flat',\n",
       " 'with',\n",
       " 'halliwells',\n",
       " 'murals',\n",
       " 'decorating',\n",
       " 'every',\n",
       " 'surface',\n",
       " 'are',\n",
       " 'terribly',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d91339c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['tokenized_text'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "199847ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aditya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stopwords.\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c7c29838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5244380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "09dac7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a7f54c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filtered_text']=df['tokenized_text'].apply(lambda x:[word for word in x if word not in sw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f3aa37d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['filtered_text'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2591097d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['tokenized_text'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4bfb6fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d9e58dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ab6cbb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stem_text']=df['filtered_text'].apply(lambda x:[stem .stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8a56ada9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonder',\n",
       " 'littl',\n",
       " 'product',\n",
       " 'film',\n",
       " 'techniqu',\n",
       " 'unassum',\n",
       " 'oldtimebbc',\n",
       " 'fashion',\n",
       " 'give',\n",
       " 'comfort',\n",
       " 'sometim',\n",
       " 'discomfort',\n",
       " 'sens',\n",
       " 'realism',\n",
       " 'entir',\n",
       " 'piec',\n",
       " 'actor',\n",
       " 'extrem',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'got',\n",
       " 'polari',\n",
       " 'voic',\n",
       " 'pat',\n",
       " 'truli',\n",
       " 'see',\n",
       " 'seamless',\n",
       " 'edit',\n",
       " 'guid',\n",
       " 'refer',\n",
       " 'william',\n",
       " 'diari',\n",
       " 'entri',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'watch',\n",
       " 'terrificli',\n",
       " 'written',\n",
       " 'perform',\n",
       " 'piec',\n",
       " 'master',\n",
       " 'product',\n",
       " 'one',\n",
       " 'great',\n",
       " 'master',\n",
       " 'comedi',\n",
       " 'life',\n",
       " 'realism',\n",
       " 'realli',\n",
       " 'come',\n",
       " 'home',\n",
       " 'littl',\n",
       " 'thing',\n",
       " 'fantasi',\n",
       " 'guard',\n",
       " 'rather',\n",
       " 'use',\n",
       " 'tradit',\n",
       " 'dream',\n",
       " 'techniqu',\n",
       " 'remain',\n",
       " 'solid',\n",
       " 'disappear',\n",
       " 'play',\n",
       " 'knowledg',\n",
       " 'sens',\n",
       " 'particularli',\n",
       " 'scene',\n",
       " 'concern',\n",
       " 'orton',\n",
       " 'halliwel',\n",
       " 'set',\n",
       " 'particularli',\n",
       " 'flat',\n",
       " 'halliwel',\n",
       " 'mural',\n",
       " 'decor',\n",
       " 'everi',\n",
       " 'surfac',\n",
       " 'terribl',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stem_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8d4ef67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonderful',\n",
       " 'little',\n",
       " 'production',\n",
       " 'filming',\n",
       " 'technique',\n",
       " 'unassuming',\n",
       " 'oldtimebbc',\n",
       " 'fashion',\n",
       " 'gives',\n",
       " 'comforting',\n",
       " 'sometimes',\n",
       " 'discomforting',\n",
       " 'sense',\n",
       " 'realism',\n",
       " 'entire',\n",
       " 'piece',\n",
       " 'actors',\n",
       " 'extremely',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'got',\n",
       " 'polari',\n",
       " 'voices',\n",
       " 'pat',\n",
       " 'truly',\n",
       " 'see',\n",
       " 'seamless',\n",
       " 'editing',\n",
       " 'guided',\n",
       " 'references',\n",
       " 'williams',\n",
       " 'diary',\n",
       " 'entries',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'terrificly',\n",
       " 'written',\n",
       " 'performed',\n",
       " 'piece',\n",
       " 'masterful',\n",
       " 'production',\n",
       " 'one',\n",
       " 'great',\n",
       " 'masters',\n",
       " 'comedy',\n",
       " 'life',\n",
       " 'realism',\n",
       " 'really',\n",
       " 'comes',\n",
       " 'home',\n",
       " 'little',\n",
       " 'things',\n",
       " 'fantasy',\n",
       " 'guard',\n",
       " 'rather',\n",
       " 'use',\n",
       " 'traditional',\n",
       " 'dream',\n",
       " 'techniques',\n",
       " 'remains',\n",
       " 'solid',\n",
       " 'disappears',\n",
       " 'plays',\n",
       " 'knowledge',\n",
       " 'senses',\n",
       " 'particularly',\n",
       " 'scenes',\n",
       " 'concerning',\n",
       " 'orton',\n",
       " 'halliwell',\n",
       " 'sets',\n",
       " 'particularly',\n",
       " 'flat',\n",
       " 'halliwells',\n",
       " 'murals',\n",
       " 'decorating',\n",
       " 'every',\n",
       " 'surface',\n",
       " 'terribly',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filtered_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d28d2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "38a8548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a678a675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aditya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "df['lemma_text']=df['filtered_text'].apply(lambda x:[lemma .lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "82d14dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonderful',\n",
       " 'little',\n",
       " 'production',\n",
       " 'filming',\n",
       " 'technique',\n",
       " 'unassuming',\n",
       " 'oldtimebbc',\n",
       " 'fashion',\n",
       " 'give',\n",
       " 'comforting',\n",
       " 'sometimes',\n",
       " 'discomforting',\n",
       " 'sense',\n",
       " 'realism',\n",
       " 'entire',\n",
       " 'piece',\n",
       " 'actor',\n",
       " 'extremely',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'got',\n",
       " 'polari',\n",
       " 'voice',\n",
       " 'pat',\n",
       " 'truly',\n",
       " 'see',\n",
       " 'seamless',\n",
       " 'editing',\n",
       " 'guided',\n",
       " 'reference',\n",
       " 'williams',\n",
       " 'diary',\n",
       " 'entry',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'terrificly',\n",
       " 'written',\n",
       " 'performed',\n",
       " 'piece',\n",
       " 'masterful',\n",
       " 'production',\n",
       " 'one',\n",
       " 'great',\n",
       " 'master',\n",
       " 'comedy',\n",
       " 'life',\n",
       " 'realism',\n",
       " 'really',\n",
       " 'come',\n",
       " 'home',\n",
       " 'little',\n",
       " 'thing',\n",
       " 'fantasy',\n",
       " 'guard',\n",
       " 'rather',\n",
       " 'use',\n",
       " 'traditional',\n",
       " 'dream',\n",
       " 'technique',\n",
       " 'remains',\n",
       " 'solid',\n",
       " 'disappears',\n",
       " 'play',\n",
       " 'knowledge',\n",
       " 'sens',\n",
       " 'particularly',\n",
       " 'scene',\n",
       " 'concerning',\n",
       " 'orton',\n",
       " 'halliwell',\n",
       " 'set',\n",
       " 'particularly',\n",
       " 'flat',\n",
       " 'halliwells',\n",
       " 'mural',\n",
       " 'decorating',\n",
       " 'every',\n",
       " 'surface',\n",
       " 'terribly',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemma_text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "28abf687",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['stem_text']\n",
    "y=df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "41540cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [one, review, mention, watch, 1, oz, episod, y...\n",
       "1        [wonder, littl, product, film, techniqu, unass...\n",
       "2        [thought, wonder, way, spend, time, hot, summe...\n",
       "3        [basic, there, famili, littl, boy, jake, think...\n",
       "4        [petter, mattei, love, time, money, visual, st...\n",
       "                               ...                        \n",
       "49995    [thought, movi, right, good, job, wasnt, creat...\n",
       "49996    [bad, plot, bad, dialogu, bad, act, idiot, dir...\n",
       "49997    [cathol, taught, parochi, elementari, school, ...\n",
       "49998    [im, go, disagre, previou, comment, side, malt...\n",
       "49999    [one, expect, star, trek, movi, high, art, fan...\n",
       "Name: stem_text, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "44acf072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7a72dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d7d614f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "267e0e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39087    [that, kept, ask, mani, fight, scream, match, ...\n",
       "30893    [watch, entir, movi, could, watch, entir, movi...\n",
       "45278    [touch, love, stori, reminisc, mood, love, dra...\n",
       "16398    [latterday, fulci, schlocker, total, abysm, co...\n",
       "13653    [first, firmli, believ, norwegian, movi, conti...\n",
       "                               ...                        \n",
       "11284    [shadow, magic, recaptur, joy, amaz, first, mo...\n",
       "44732    [found, movi, quit, enjoy, fairli, entertain, ...\n",
       "38158    [avoid, one, terribl, movi, excit, pointless, ...\n",
       "860      [product, quit, surpris, absolut, love, obscur...\n",
       "15795    [decent, movi, although, littl, bit, short, ti...\n",
       "Name: stem_text, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eb50c843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33553    [realli, like, summerslam, due, look, arena, c...\n",
       "9427     [mani, televis, show, appeal, quit, mani, diff...\n",
       "199      [film, quickli, get, major, chase, scene, ever...\n",
       "12447    [jane, austen, would, definit, approv, onegwyn...\n",
       "39489    [expect, somewhat, high, went, see, movi, thou...\n",
       "                               ...                        \n",
       "28567    [although, casper, van, dien, michael, rooker,...\n",
       "25079    [like, movi, wasnt, realli, sure, start, watch...\n",
       "18707    [ye, nonsingaporean, cant, see, what, big, dea...\n",
       "15200    [far, film, go, likabl, enough, entertain, cha...\n",
       "5857     [saw, anatomi, year, ago, dub, friend, hous, d...\n",
       "Name: stem_text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "41abe9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39087    negative\n",
       "30893    negative\n",
       "45278    positive\n",
       "16398    negative\n",
       "13653    negative\n",
       "           ...   \n",
       "11284    positive\n",
       "44732    positive\n",
       "38158    negative\n",
       "860      positive\n",
       "15795    positive\n",
       "Name: sentiment, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bce8bd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33553    positive\n",
       "9427     positive\n",
       "199      negative\n",
       "12447    positive\n",
       "39489    negative\n",
       "           ...   \n",
       "28567    negative\n",
       "25079    positive\n",
       "18707    positive\n",
       "15200    negative\n",
       "5857     positive\n",
       "Name: sentiment, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7ea0ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e867d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4c27248d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39087    [that, kept, ask, mani, fight, scream, match, ...\n",
       "30893    [watch, entir, movi, could, watch, entir, movi...\n",
       "45278    [touch, love, stori, reminisc, mood, love, dra...\n",
       "16398    [latterday, fulci, schlocker, total, abysm, co...\n",
       "13653    [first, firmli, believ, norwegian, movi, conti...\n",
       "                               ...                        \n",
       "11284    [shadow, magic, recaptur, joy, amaz, first, mo...\n",
       "44732    [found, movi, quit, enjoy, fairli, entertain, ...\n",
       "38158    [avoid, one, terribl, movi, excit, pointless, ...\n",
       "860      [product, quit, surpris, absolut, love, obscur...\n",
       "15795    [decent, movi, although, littl, bit, short, ti...\n",
       "Name: stem_text, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0d96d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=tfidf.fit_transform(X_train.apply(lambda x:''.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e40a71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=tfidf.transform(X_test.apply(lambda x:''.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dee5f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "47a0e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "y_train=le.fit_transform(y_train)\n",
    "y_test=le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "33312f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "15f9f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "54bfe29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6d3dad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 39741)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ba6bafba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 39741)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fba23f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "238b53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b9ce1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "53ef1a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aditya\\OneDrive\\Desktop\\Programming\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Dense(128,activation='relu',input_shape=(X_train.shape[1],)),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(2,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c34fc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ecfb1eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 26ms/step - accuracy: 0.4991 - loss: 0.6932\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - accuracy: 0.9157 - loss: 0.2125\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 8.3034e-06\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.2311e-06\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.0782e-06\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.8506e-06\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.4352e-07\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.9570e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.3963e-08\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.2758e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e1122294f0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "233d539b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ed3f321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (1.36.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (5.3.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (24.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (16.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (8.4.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (4.11.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aditya\\onedrive\\desktop\\programming\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ad53c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Assuming your trained model is named 'model'\n",
    "joblib.dump(model, 'model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf.pkl')\n",
    "\n",
    "# Load the model and TF-IDF vectorizer\n",
    "model = joblib.load('model.pkl')\n",
    "tf_idf_vector = joblib.load('tfidf.pkl')\n",
    "\n",
    "# Initialize NLTK tools\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(review):\n",
    "    cleaned_review = re.sub('<.*?>', '', review)\n",
    "    cleaned_review = re.sub(r'[^\\w\\s]', '', cleaned_review)\n",
    "    cleaned_review = cleaned_review.lower()\n",
    "    tokenized_review = word_tokenize(cleaned_review)\n",
    "    filtered_review = [word for word in tokenized_review if word not in stop_words]\n",
    "    stemmed_review = [stemmer.stem(word) for word in filtered_review]\n",
    "    tfidf_review = tf_idf_vector.transform([' '.join(stemmed_review)])\n",
    "    sentiment_prediction = model.predict(tfidf_review)\n",
    "    print(sentiment_prediction)\n",
    "    predicted_class_index=np.argmax(sentiment_prediction)\n",
    "    print(predicted_class_index)\n",
    "    if predicted_class_index > 0.6:  # Adjust threshold as needed\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "# Streamlit UI\n",
    "st.title('Sentiment Analysis')\n",
    "review_to_predict = st.text_area('Enter your review here:')\n",
    "if st.button('Predict Sentiment'):\n",
    "    predicted_sentiment = predict_sentiment(review_to_predict)\n",
    "    st.write(\"Predicted Sentiment:\", predicted_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2901568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!streamlit run Main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "23f16a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ipynb-py-convert Sentiment_Analysis.ipynb Sentiment_Analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a969fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipynb-py-convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed209e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
